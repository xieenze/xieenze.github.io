<!DOCTYPE html>
<html lang="en">
    
<head>
	<meta charset="utf-8" />
	<title>Enze Xie</title>
	<!--Custom fonts. To improve load times, remove this and update the h1 styling in style.css--> 
	<link href='http://fonts.googleapis.com/css?family=Lato:300,700' rel='stylesheet' type='text/css'>
	<!-- stylesheets -->
	<link rel="stylesheet" href="assets/cherryzhao_css/style.css" type="text/css" />
	<!-- favicon -->
	<link rel="shortcut icon" href="https://www.nvidia.com/favicon.ico">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
	
<body>
	<!-- Header-->
	<header>
		<h1>Enze Xie (谢恩泽)</h1>
	</header>
	
	<div class="container">
			<!-- about me -->
			<section class="center">
				<div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
				<span style=" font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
					<strong>About</strong>
				</span>
				</div>
				<br>
				<br>
				<div class="container">
					<div class="row">
						<div class="grid-2">
							<img src="assets/imgs/enze_2.jpg">
							<div style="text-align: center; margin-top: 10px; display: flex; justify-content: center;">
                                <a href="mailto:xieenze@connect.hku.hk" style="margin: 0 15px; text-decoration: none; color: #666; text-align: center;">
                                    <i class="fa fa-envelope fa-2x"></i><br>Email
                                </a>
                                <a href="https://scholar.google.com/citations?user=42MVVPgAAAAJ&hl=zh-CN" style="margin: 0 15px; text-decoration: none; color: #666; text-align: center;">
                                    <i class="fa fa-graduation-cap fa-2x"></i><br>Scholar
                                </a>
                                <a href="https://github.com/xieenze" style="margin: 0 15px; text-decoration: none; color: #666; text-align: center;">
                                    <i class="fa fa-github fa-2x"></i><br>GitHub
                                </a>
                                <a href="https://www.linkedin.com/in/enze-xie-9b0831125" style="margin: 0 15px; text-decoration: none; color: #666; text-align: center;">
                                    <i class="fa fa-linkedin fa-2x"></i><br>LinkedIn
                                </a>
                            </div>
						</div>
						<div class="grid-4">
                            <p style=" text-align:left;">
                                I am a <a href="https://research.nvidia.com/person/enze-xie">Senior Research Scientist</a> at <a href="https://research.nvidia.com/">NVIDIA Research</a> working with Prof. <a href="https://songhan.mit.edu/">Song Han</a>. 
                                I am also a visiting researcher at <a href="https://hanlab.mit.edu/">MIT HAN Lab</a>.
                                I was a Principal Researcher and Research Lead (in Generative AI) at <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a> (Hong Kong).
                                I obtained my Ph.D. degree from the Department of Computer Science, <a href="https://www.cs.hku.hk/">The University of Hong Kong</a> in 2022.
                                My advisor is Prof. <a href="http://luoping.me/">Ping Luo</a> and my co-advisor is Prof. <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a>.
                                I also work very closely with my friend <a href='https://whai362.github.io/'>Wenhai Wang</a>.
                                I was fortunate to work with 
                                Prof. <a href="https://cshen.github.io/">Chunhua Shen</a> (UofAdelaide), 
                                Prof. <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a> (CalTech),
                                and Prof. <a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a> (UofT).
                                During my PhD study, I collaborated with several researchers in industry e.g. Facebook and NVIDIA.
                                <br>
                                <br>
                                My research interest is solving challenging problems in generative AI, computer vision and deep learning. 
                                <!-- I did some works on instance-level detection and self/semi/weak-supervised learning. -->
                                I developed a few well-known computer vision algorithms including: 
                                <ul style="margin: 0; padding-left: 40px; line-height: 1.1;">
                                    <li style="margin-bottom: 0px;"><a href='http://arxiv.org/abs/1909.13226'>PolarMask</a> (Rank 10 in CVPR 2020 Top-10 Influential Papers).</li>
                                    <li style="margin-bottom: 0px;"><a href="https://arxiv.org/abs/2102.12122">PVT</a> (Rank 2 in ICCV 2021 Top-10 Influential Papers).</li>
                                    <li style="margin-bottom: 0px;"><a href="https://arxiv.org/abs/2105.15203">SegFormer</a> (Rank 3 in NeurIPS 2021 Top-10 Influential Papers).</li>
                                    <li style="margin-bottom: 0px;"><a href="https://arxiv.org/abs/2203.17270">BEVFormer</a> (Rank 6 in ECCV 2022 Top-10 Influential Papers).</li>
                                </ul>
                                <!-- I co-developed <a href='https://github.com/open-mmlab/OpenSelfSup'>OpenSelfSup (now mmselfsup)</a>, a popular self-supervised learning framework with 2k+ github stars. -->
                                <!-- <br>
                                <br> -->
                                <!-- <span style="color:red">I am looking for motivated students and collaborators. If you are interested in working with me on computer vision and machine learning research, please feel free to reach out with your CV.</span> -->
                                <br>
                                <br>
                            </p>
						</div>
					</div>
				</div>
			</section>
			
			<!-- News Section -->
			<section class="center">
				<div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
				<span style=" font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
					<strong>News</strong>
					<button onclick="toggleNews()" id="newsToggleBtn" style="background: none; border: none; font-size: 0.8em; cursor: pointer; color: #666;">
						[Show Less]
					</button>
				</span>
				</div>
				<br>
				<br>
				<div class="container">
					<div class="row">
						<div class="grid-6">
							<ul id="newsList" style="margin: 0; padding-left: 20px; list-style-type: none; line-height: 1.4;">
								<li style="margin-bottom: 5px;">[2025.02] Co-authored book<a href="https://item.jd.com/14943704.html">《计算机视觉十讲》</a> (Ten Lectures on Computer Vision) has been published!</li>
								<li style="margin-bottom: 5px;">[2025.01] 5 papers accepted to ICLR 2025 (1 Oral, 1 Spotlight).</li>
								<li style="margin-bottom: 5px;">[2024.12] Serve as Area Chair for ICCV 2025 and Guest Editor for Pattern Recognition.</li>
								<li style="margin-bottom: 5px;">[2024.08] 1 paper accepted to Nature Communications Engineering. (The first time submitted a paper to Nature and got accepted!)</li>
								<li style="margin-bottom: 5px;">[2024.07] 3 paper accepted to ECCV, 1x RA-L and 1x TMLR.</li>
								<li style="margin-bottom: 5px;">[2024.04] Back to NVIDIA Research! Join the Efficient AI team.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2024.01] 6 papers accepted to ICLR 2023 (1 Oral, 1 Spotlight) and 1 paper accepted to CVPR 2024.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2023.11] 1 survey paper accepted to TPAMI.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2023.09] 4 papers accepted to NeurIPS 2023.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2023.07] 5 papers accepted to ICCV 2023 (2 Oral) and 1 paper accepted to TPAMI.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2023.05] 1 paper accepted to ACL 2023.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2022.08] Obtained my Ph.D. degree from HKU and join Huawei Noah's Ark Lab.</li>
								<li class="hideable-news" style="margin-bottom: 5px;">[2019.10] Join HKU MMLab as a PhD student and play computer vision.</li>
							</ul>
						</div>
					</div>
				</div>
			</section>
			<br>
			<br>


            <!-- Selected Publications -->
            <section class="spotlight">
                <div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
                <span style=" font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
                    <strong>Selected Publications</strong>
                    <a href="https://scholar.google.com/citations?user=42MVVPgAAAAJ&hl=zh-CN" style="background: none; border: none; font-size: 1em; cursor: pointer; color: #0066cc; text-decoration: none;">
                        [Full List]
                    </a>
                </span>
                </div>
                <br>
                <br>


                <!-- SANA 1.5 -->
                <div class="container">
                    <div class="row">
                        <div class="grid-2" style="height:200px; line-height:200px; ">
                            <img src="assets/imgs/SANA1.5.png" style="display: inline-block; vertical-align: middle;">
                        </div>
                        <div class="grid-4">
                            <h3>SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer</h3>
                            <p>Enze Xie*, Junsong Chen*, Yuyang Zhao, Jincheng Yu, Ligeng Zhu, Yujun Lin, Zhekai Zhang, Muyang Li, Junyu Chen, Han Cai, Bingchen Liu, Daquan Zhou, Song Han</p>
                            <p><i>arXiv 2025</i></p>
                            <a href="https://arxiv.org/abs/2501.18427">arXiv</a>
                            <a href="https://github.com/NVlabs/Sana">Code</a>
                            <a href="https://nv-sana.mit.edu/">Demo</a>
                        </div>
                    </div>
                </div>
                <br>

                <!-- SANA -->
                <div class="container">
                    <div class="row">
                        <div class="grid-2" style="height:200px; line-height:200px; ">
                            <img src="assets/imgs/sana.png" style="display: inline-block; vertical-align: middle;">
                        </div>
                        <div class="grid-4">
                            <h3>SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers</h3>
                            <p>Enze Xie*, Junsong Chen*, Junyu Chen, Han Cai, Haotian Tang, Yujun Lin, Zhekai Zhang, Muyang Li, Ligeng Zhu, Yao Lu, Song Han</p>
                            <p><i>ICLR 2025 <span style="color:red">(Oral)</span> </i></p>
                            <a href="https://nvlabs.github.io/Sana">Project</a>
                            <a href="https://arxiv.org/abs/2410.10629">arXiv</a>
                            <a href="https://github.com/NVlabs/Sana">Code</a>
                        </div>
                    </div>
                </div>
                <br>
            
            <!-- PixArt-Σ -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="https://pixart-alpha.github.io/PixArt-sigma-project/static/images/samples/others_webp/4K_image.webp" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>PIXART-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation</h3>
                        <p>Junsong Chen*, Chongjian Ge*, Enze Xie*<sup>†</sup>, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, Zhenguo Li</p>
                        <p><i>ECCV 2024</i></p>
                        <a href="https://pixart-alpha.github.io/PixArt-sigma-project/">Project</a>
                        <a href="https://arxiv.org/abs/2403.04692">arXiv</a>
                        <a href="https://github.com/PixArt-alpha/PixArt-sigma">Code</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- PixArt-α -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="https://pixart-alpha.github.io/static/images/carousel/carousel1.png" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis</h3>
                        <p>Junsong Chen*, Jincheng Yu*, Chongjian Ge*, Lewei Yao*, Enze Xie<sup>†</sup>, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, Zhenguo Li</p>
                        <p><i>ICLR 2024 <span style="color:red">(Spotlight)</span></i></p>
                        <a href="https://pixart-alpha.github.io/">Project</a>
                        <a href="https://arxiv.org/abs/2310.00426">arXiv</a>
                        <a href="https://github.com/PixArt-alpha/PixArt-alpha">Code</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- DiffFit -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="assets/imgs/difffit.png" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning</h3>
                        <p>Enze Xie, Lewei Yao, Han Shi, Zhili Liu, Daquan Zhou, Zhaoqiang Liu, Jiawei Li, Zhenguo Li</p>
                        <p><i>ICCV 2023 <span style="color:red">(Oral)</span></i></p>
                        <a href="https://arxiv.org/abs/2304.06648">arXiv</a>
                        <a href="https://github.com/lawrence-cj/LLaMA-DiffFit">Code</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- BEVFormer -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="https://simg.baai.ac.cn/uploads/2022/07/8a35f439fa5cc6749debec12905a7bf8.gif" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</h3>
                        <p>Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Qiao Yu, Jifeng Dai</p>
                        <p><i>ECCV 2022 <span style="color:gray">(ECCV 2022 Top-10 Influential Papers)</span></i></p>
                        <a href="https://arxiv.org/abs/2203.17270">arXiv</a>
                        <a href="https://github.com/fundamentalvision/BEVFormer">Code</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- FAN -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; text-align: center;">
                        <iframe width="100%" height="100%" 
                            src="https://www.youtube.com/embed/t79E4gq4L-A?autoplay=1&mute=1&loop=1&playlist=t79E4gq4L-A" 
                            frameborder="0" 
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                            allowfullscreen
                            style="max-width: 100%; display: inline-block; vertical-align: middle;">
                        </iframe>
                    </div>
                    <div class="grid-4">
                        <h3>Understanding The Robustness in Vision Transformers</h3>
                        <p>Daquan Zhou, Zhiding Yu, Enze Xie, Chaowei Xiao, Anima Anandkumar, Jiashi Feng, Jose M. Alvarez</p>
                        <p><i>ICML 2021 <span style="color:red">(Spotlight)</span></i></p>
                        <a href="https://arxiv.org/abs/2204.12451">arXiv</a>
                        <a href="https://github.com/NVlabs/FAN">Code</a>
                        <a href="https://www.youtube.com/watch?v=nBjXyoltCHU">NVIDIA Demo</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- SegFormer -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/07/ViT-image-processing.png" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</h3>
                        <p>Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkuma, Jose M. Alvarez, Ping Luo</p>
                        <p><i>NeurIPS 2021 <span style="color:gray">(NeurIPS 2021 Top-10 Influential Papers)</span></i></p>
                        <a href="https://arxiv.org/abs/2105.15203">arXiv</a>
                        <a href="https://github.com/NVlabs/SegFormer">Code</a>
                        <a href="https://www.youtube.com/watch?v=nBjXyoltCHU">NVIDIA Demo</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- Pyramid Vision Transformer -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="assets/imgs/pvt1.png" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions</h3>
                        <p>Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao</p>
                        <p><i>ICCV 2021 <span style="color:red">(Oral)</span> <span style="color:gray">(ICCV 2021 Top-10 Influential Papers)</span></i></p>
                        <a href="https://arxiv.org/abs/2102.12122">arXiv</a>
                        <a href="https://github.com/whai362/PVT">Code</a>
                    </div>
                </div>
            </div>
            <br>

            <!-- PolarMask -->
            <div class="container">
                <div class="row">
                    <div class="grid-2" style="height:200px; line-height:200px; ">
                        <img src="assets/imgs/PolarMask.PNG" style="display: inline-block; vertical-align: middle;">
                    </div>
                    <div class="grid-4">
                        <h3>PolarMask: Single Shot Instance Segmentation with Polar Representation</h3>
                        <p>Enze Xie*, Peize Sun*, Xiaoge Song*, Wenhai Wang, Ding Liang, Chunhua Shen, Ping Luo</p>
                        <p><i>CVPR 2020 <span style="color:red">(Oral)</span> <span style="color:gray">(CVPR20 Top-10 Influential Papers)</span></i></p>
                        <a href="http://arxiv.org/abs/1909.13226">arXiv</a>
                        <a href="https://github.com/xieenze/PolarMask">Code</a>
                    </div>
                </div>
            </div>
            <br>        

            </section>
            <br>  
		

		<!--Academic Service Section -->
		<section class="center">
			<div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
			<span style=" font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
				<strong>Academic Service</strong>
			</span>
			</div>
			<br>
			<br>
			<div class="container">
				<div class="row">
					<div class="grid-6">
						<table style="width:100%; border-collapse: collapse;">
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Area Chair for ICCV 2025</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Guest Editor for Pattern Recognition</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Organizer for <a href="https://sites.google.com/view/t4v-cvpr22">T4V: Transformers for Vision Workshop</a> at CVPR 2022</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Journal Reviewer for TPAMI, IJCV, RA-L, T-MM</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Conference Reviewer for ICML, NeurIPS, CVPR, ICCV, ECCV, IROS, IJCAI, AAAI, WACV, ACCV</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">SPC for IJCAI21,22</td>
							</tr>
						</table>
					</div>
				</div>
			</div>
		</section>
		<br>
		<br>

		<!-- Honours and Awards Section -->
		<section class="center">
			<div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
			<span style=" font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
				<strong>Honours and Awards</strong>
			</span>
			</div>
			<br>
			<br>
			<div class="container">
				<div class="row">
					<div class="grid-6">
						<table style="width:100%; border-collapse: collapse;">
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">KAUST AI Rising Star Award</td>
								<td style="padding-bottom: 8px; text-align: right;">2025</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">WAIC Rising Star Award (15 awardees globally each year)</td>
								<td style="padding-bottom: 8px; text-align: right;">2024</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;"><a href="https://elsevier.digitalcommonsdata.com/public-files/datasets/btchxktzyw/files/7bad01c2-63e8-4ed2-94f2-4af4b3b0a4fe/file_downloaded">Top 2% Scientists Worldwide 2023</a> by Stanford University</td>
								<td style="padding-bottom: 8px; text-align: right;">2023</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;"><a href="https://juejin.cn/post/7249918880910180413">WAIC Youth Outstanding Paper</a> (10 papers selected)</td>
								<td style="padding-bottom: 8px; text-align: right;">2023</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Most Popular Speakers in <a href="https://mp.weixin.qq.com/s/GfeYJ6zpGYaVHs2kKpjQcA">TechBeat 2022</a></td>
								<td style="padding-bottom: 8px; text-align: right;">2022</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">NVIDIA Graduate Fellowship Finalist Award (The first candidate from Chinese University in 21 years)</td>
								<td style="padding-bottom: 8px; text-align: right;">2022</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">NeurIPS 2021 Outstanding Reviewer Award (top 8% of reviewers)</td>
								<td style="padding-bottom: 8px; text-align: right;">2021</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Hong Kong and China Gas Company Limited Postgraduate Prize</td>
								<td style="padding-bottom: 8px; text-align: right;">2021</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Rank 1 in <a href="https://naic.pcl.ac.cn/api/backstatic/%E5%86%B3%E8%B5%9B%E8%8E%B7%E5%A5%96%E5%90%8D%E5%8D%95%E5%85%AC%E5%B8%83-2020%E5%B9%B4%E5%85%A8%E5%9B%BD%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E8%B5%9B.pdf">National Artificial Intelligence Competition - Remote Sensing Segmentation</a> <i><font color="red">(bonus 1,000,000 RMB)</font></i></td>
								<td style="padding-bottom: 8px; text-align: right;">2020</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Rank 1 in <a href="https://www.kaggle.com/c/open-images-2019-instance-segmentation/leaderboard">Google Open Images 2019 - Instance Segmentation</a></td>
								<td style="padding-bottom: 8px; text-align: right;">2019</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Rank 1 in <a href="https://rrc.cvc.uab.es/?ch=14&com=evaluation&task=1">ICDAR 2019 Arbitrary-Shaped Text Detection</a></td>
								<td style="padding-bottom: 8px; text-align: right;">2019</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Rank 2 in <a href="https://rrc.cvc.uab.es/?ch=16&com=evaluation&task=1">ICDAR 2019 Large-scale Street View Text Detection</a></td>
								<td style="padding-bottom: 8px; text-align: right;">2019</td>
							</tr>
							<tr>
								<td style="padding-bottom: 8px; text-align: left;">Outstanding Master Thesis Award, Tongji University</td>
								<td style="padding-bottom: 8px; text-align: right;">2019</td>
							</tr>
						</table>
					</div>
				</div>
			</div>
		</section>
		<br>
		<br>

        <!--Experience-->
        <div class="center">
            <div style="width: 100%; height: 20px; border-bottom: 1px solid #ccc; text-align: center">
                <span style="font-size: 1.8em; font-family: 'Lato', sans-serif; background-color: #FFF; padding: 0 10px;">
                    <strong>Experience and Collaborations</strong>
                </span>
            </div>
            <br>
            <br>
            <div style="text-align: center;">
                <img src="assets/imgs/experience.png" style="display: inline-block; max-width: 100%;"> 
            </div>
        </div>
        <br>
        <br>

		<!--Footer-->
		<footer class="center">
			<hr>
			<span>&copy; Enze Xie | Borrowed from <a href="http://nxzhao.com/">Cherry Zhao</a> | Last updated: March 2025</span>
		</footer>
		
	</div><!-- End Container -->

	<!-- Add this script at the end of your body tag -->
	<script>
		// Add this style to your head section or in a style tag
		document.head.insertAdjacentHTML('beforeend', `
			<style>
				.hideable-news {
					display: block;
				}
				.news-collapsed .hideable-news {
					display: none;
				}
			</style>
		`);
		
		function toggleNews() {
			const newsList = document.getElementById('newsList');
			const toggleBtn = document.getElementById('newsToggleBtn');
			
			if (newsList.classList.contains('news-collapsed')) {
				newsList.classList.remove('news-collapsed');
				toggleBtn.textContent = '[Show Less]';
			} else {
				newsList.classList.add('news-collapsed');
				toggleBtn.textContent = '[Show More]';
			}
		}
		
		// Initialize as collapsed
		document.getElementById('newsList').classList.add('news-collapsed');
		document.getElementById('newsToggleBtn').textContent = '[Show More]';
	</script>
</body>
</html>
